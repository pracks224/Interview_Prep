## About me

Hello, my name is Prakash. I am in the process of creating a repository to store all of my interview questions in one central location. This will allow me to better prepare for future interviews and keep track of the questions I have been asked in the past. I believe that this will also help me to identify patterns and areas where I may need to improve my skills. Thank you for your assistance in helping me to achieve this goal.

### Important Questions
<details>
  <summary>Set -1 : Interview Questions </summary>
  
    1. How to handle Exception in SpringBoot? (hint. https://levelup.gitconnected.com/exception-handling-with-examples-f6ed09452cb2)
    2. What is the @controllerAdvice in springboot? - Exception Handling
    3. How to do transaction management in Spring boot application? (https://www.scaler.com/topics/spring-boot/transaction-management-in-spring-boot/)
    4. How Spring- Security works.(https://www.scaler.com/topics/spring-boot/spring-security/).
    5. SpringBoot with OAuth2.How it works? (https://howtodoinjava.com/spring-boot2/oauth2-auth-server/)
    6. How to do CORS configuration in Spring Boot ?(https://howtodoinjava.com/spring-boot2/spring-cors-configuration/)
    7. How to add Global CORS configuration for the application?
    8. What is the use @Configuration? //Bean Definitions
    9. What is a passwordEncoder ? // enforeces password encoding ,plain text password wont allowed
    10. CQRS design patterns in Microservices?
    11. 
    12. Design a URL Shortner (tinyurl)
    13. Design a web crawler.(https://github.com/preslavmihaylov/booknotes/blob/master/system-design/system-design-interview/chapter10/README.md)
    14. Design a notification System
    15. Method overloading vs Method Overiding.
    16. Method overriding passing null object . //Subclass object gets the preference which is String in this case
    17. Differnce between String,StringBuilder and StringBUffer?
    18. How String concatnation operator internally works ?
    19. Best/efficient way to join String ?
    20. What is Method references?
    21. Anagram check in Java?
    22. what is groupingBy? (https://mkyong.com/java8/java-8-collectors-groupingby-and-mapping-example/)
    23. How can you create a comparator?
    24. What are SOLID principles of Object Oriented Programming? (https://www.freecodecamp.org/news/solid-principles-explained-in-plain-english/)
    25. What is transient variable ?
    26. https://www.interviewgrid.com/interview_questions/java \*\*\*\* Pending
    27. What is Flattening?
    28. Return a list of all unique characters for a list of words?
    29. Return Square of numbers of list of integers using Stream
    30. Given two lists of numbers, how would you return all pairs of numbers? For example, givenalist [1, 2, 3] and a list [3, 4] you should return [(1, 3), (1, 4), (2, 3), (2, 4), (3, 3), (3, 4)]. Forsimplicity, you can represent a pair as an array with two elements.
    31. How would you extend the previous example to return only pairs whose sumis divisibleby3?For example, (2, 4) and (3, 3) are valid.
    32. What is Short-circuiting evaluation in stream ?
    33. When to use findFirst and findAny.
    34. Summing all the element of a list.
    35. Describe the use of Optional in Java?
    36. Describe the differnce between map,flatmap and reducce
    37. Describe the use case of JSON Web Token?
    38. How can you disable the Autoconfiguration in Spring boot Application?
    39. How do Microservice communicate each other?
    40. Describe the API Gateway design pattern for Micro service?
    41. Describe some principle of Mircro Service deployment?
    42. Describe the Circuit Breaker Design Pattern?
</details>
<details>
  <summary>Set -2 : Interview Questions </summary>

  43. Javascript Event Loop and Call Stack Explain?
  44. Implement an algorithm to determine if a string has all unique characters. What if you
      cannot use additional data structures? (Bitwise way to understand)
  45. One string permutaion of other
  46. URLfy of String (Yet to Solve) %%%%%%%%% %%%%% All below %%%%%% %%%%%%%
  47. Palindrom Permutation
  48. One Away: There are three types of edits that can be performed on strings: insert a character,
      remove a character, or replace a character. Given two strings, write a function to check if they are
      one edit (or zero edits) away.
      EXAMPLE
      pale, ple -> true
      pales, pale -> true
      pale, bale -> true
      pale, bae -> false
  
  49. String compression For example, the string aabcccccaaa would become a2blc5a3
  50. String Rotation: Assume you have a method i 5Su b 5 tr ing which checks if one word is a substring
      of another. Given two strings, 51 and 52, write code to check if 52 is a rotation of 51 using only one
      call to i5Sub5tring (e.g., "waterbottle" is a rotation of"erbottlewat").
  
  ### System Design
  
  - https://github.com/black-shadows/System-Design - Well documented
  
  51. Design Data Intensive Application Book Overview
  52. Consistency Hashing
  53. CAP theorem
  54. Isolation levels
  55. 2PL
  56. How to make the API end point faster. (https://medium.com/design-bootcamp/how-i-optimized-an-api-endpoint-to-make-it-10x-faster-2f5fe9a84bd9)
  
  ## Java Script
  
  57. How to create object in Javascript?
  58. Difference between Object.freeze() and const in JavaScript ?
  
  59. How to deep-freeze an object in JavaScript ? hint (https://github.com/pracks224/Interview_Prep/blob/main/deepfreeze.js)
  
  60. Implement sum(2)(3)() (Currying funtions- is also a higher order function ?(https://github.com/pracks224/Interview_Prep/blob/main/deepfreeze.js)
  
  61. What is the difference between call(),apply() and bind() methods?
  
  ## Java OOps
  
  62. Functional Programming Using Java
  
  ## Java Collections
  
  63. How ConcurrentHashMap works ?
  64. How HashSet works internally ?
  65. What is Consisten Hashing?
</details>

<details>
  <summary>Set-3 Microservices Using Spring Boot</summary>
  
  66. What is Spring Boot and what are its Benefits?
  67. What makes Spring Boot superior to JAX-RS?
  68. What Spring Boot features help develop Microservices Applications?
  69. Why Spring Boot is preferred over any other framework?
  70. What are the key dependencies of Spring Boot?
  71. What are the advantages of Spring Boot?
  72. What are the features of Spring Boot?
  73. How do you create a Spring Boot application using Maven?
  74. How do you create a Spring Boot project using Spring Initializer?
  75. How do you create a Spring Boot project using boot CLI?
  76. How do you create a simple Spring Boot application?
  77. What are the Spring Boot Annotations?
  78. What are the Spring Boot properties?
  79. What are the Spring Boot Starters?
  80. What is Spring Boot Actuator?
  81. What is thyme leaf?
  82. How to use thyme leaf?
  83. How do you connect Spring Boot to the database using JPA?
  84. How to connect the Spring Boot application to a database using JDBC?
  85. What is @RestController annotation in Spring Boot?
  86. What is @RequestMapping annotation in Spring Boot?
  87. How do you create a Spring Boot application using Spring Starter Project Wizard?
  88. Spring Vs Spring Boot? Or Why Spring Boot over Spring?
  89. What annotations are used to create an Interceptor?
  90. What is a Swagger in Spring Boot?
  91. What are Profiles in Spring Boot?
  92. What differentiates Spring Data JPA and Hibernate?
  93. How are the @RestController and @Controller Annotation different?
  94. How does Spring Boot works?
  95. What does the @SpringBootApplication annotation do internally?
  96. What is the purpose of using @ComponentScan in the class files?
  97. How does a spring boot application get started?
  98. Can we create a non-web application in Spring Boot?
  99. Can we override or replace the Embedded tomcat server in Spring Boot?
  100. Can we disable the default web server in the Spring boot application?
  101. How to disable a specific auto-configuration class?
  102. Describe the flow of HTTPS requests through the Spring Boot application?
  103. What is the difference between RequestMapping and GetMapping?
  104. What is the use of Profiles in spring boot?
  105. What is Spring Actuator? What are its advantages?
  106. How to enable Actuator in Spring boot application?
  107. What are the actuator-provided endpoints used for monitoring the Spring boot application?
  108. How to get the list of all the beans in your Spring boot application?
  109. How to check the environment properties in your Spring boot application?
  110. How to enable debugging log in the spring boot application?
  111. Where do we define properties in the Spring Boot application?
  112. What is dependency Injection?
  113.  What is an IOC container?
  114.  What are some essential features of Spring Security?
  115.  What is Spring security authentication and authorization?
  116.  What do you mean by basic authentication?
  117.  What do you mean by digest authentication?
  118.  What do you mean by session management in Spring Security?
  119.  Explain SecurityContext and SecurityContext Holder in Spring security.
  120.  Explain spring security OAuth2.
  121. What do you mean by OAuth2 Authorization code grant type?
  122.  What is method security and why do we need it?
  123.  What do you mean by HASHING in spring security?
  124.  Explain salting and its usage.
  125.  What is PasswordEncoder?
  126.  Explain AbstractSecurityInterceptor in spring security?
  127.  Is security a cross-cutting concern?
  128. What is SpEL (Spring Expression Language)?
  129. Name security annotations that are allowed to use SpEL.
  130. Explain what is AuthenticationManager in Spring security.
  131. Explain what is ProviderManager in Spring security.
  132. What is JWT?
  134. What is Spring Security Filter Chain?
  135. Explain how the security filter chain works.
  136. Name some predefined filters used in spring security and write their functions.
  137. What do you mean by principal in Spring security?
  138. Can you explain what is DelegatingFilterProxy in spring security?
  139. Can you explain what is FilterChainProxy in spring security?
  140. What is the intercept-url pattern and why do we need it?
  141. Does order matter in the intercept-url pattern? If yes, then in which order should we write it?
  142. State the difference between ROLE_USER and ROLE_ANONYMOUS in a spring intercept-url configuration.
  143. State the difference between @PreAuthorize and @Secured in Spring security.
  144. State the difference between @Secured and @RolesAllowed.
  </details>
  
  <details>
    <summary>Building Microservices (Designing Fine Grained System </summary>
  145. Domain Driven Design - Can you give one example
            Virtulization platform allow us to provison and resize our machine at will, with infrastructure automation giving us a way to handle at scale.
 146. What are Micro services?
     Ans: Small,autonomus services that work together.
 147. Key Benefits of Micro Services 
     - Technology Heterogenity
     - Resilinece -> If one component fails ,it wont cascade
     - Scaling  -> With monolithic, we have scale everything ,but here one small unit only
     - Ease of deployment
     - Organizational Allignments - NO large team,NO Large DB etc
     - Optimizing of replacibility - Easy replacement after reaching end of life
 
 148. How to Model Services
     1. Loose coupling and High cohesion makes a services good. 
        -  Whats is Loose coupling? Ans: When services are loosly coupled, a change in one service should not require a change in another.
        -  What is High cohesion? Ans: Related behaviors sit together. So we have to find out the boundaries within our problem domain that help ensures that related behaviours in one place.
     2. What do you mean by Bounded Context?
        Ans : A Bounded Context is a central pattern in DDD (Domain-Driven Design), which deals with collaboration across large models and teams. DDD breaks large models down into multiple contexts to make them more manageable. Additionally, it explains their relationship explicitly. The concept promotes an object-oriented approach to developing services bound to a data model and is also responsible for ensuring the integrity and mutability of said data model.   Eg. In Music corp - Finance and warehouse are two bounded context.
    3.  https://github.com/rootusercop/Free-DevOps-Books-1/blob/master/book/Building%20Microservices%20-%20Designing%20Fine-Grained%20Systems.pdf Page - 34
 
 **[⬆ Back to Top](#table-of-contents)**   
  </details>

## Kafka

<details>
  <summary>Important Notes to revise</summary>  
 
  ```diff
    a) What is kafka Cluster? 
       - Group of Kafka brokers.  
    b) What is Kafka broker -> Its the server where Kafka instances are running.
    c) Producer -> Writes new data to the kafka cluster (data dal dega)
    d) Consumer - > Kaffka cluster se data utha ta hai
    e) Zookeeper -> Monitors the Kafka cluster health
    f) Connects -> If you have to pull data from external source ( configurable ). We dont need to write any code
    g) Stream -> to transformation the data 
 ```
 ##### Kafka Topics 
 - These are like tables of databse
 - They live inside the broker
 -  Producers produces the messages and send to topics
 -  Topics has partions
 - Producers can directly send the data to partion or topics
 
 ##### Kafka Partiontions 
 
 - Topics has many partions like p0 p1 p2 ..
 - Partions where actual messages stores.
 - While creating topics,number partions will be decided
 -  Partions are ordered and immutable sequence
 - Partions are in increased order id called offset
 - Each partion is independent of each other.
 - All the trannsactions stores in distributed log files.
 
 ##### How and why to send messages to KAFKA keys ?
 
 - When producers send messages to Topics/Partions , It will insert into Partions in  round robin fashion
      Producer - Send messages m1,m2,m3, m4
 - Let's say Topics has p1,p2 partions,Then messages will insert into p1 - m1 -> p2 - m2  -> p1- m3 -> p2 - m4 etc
      The problem with this approach is it fetches in unorders fashion. To avoid we have to pass the message with keys
 -  When message passed with keys, partiotoner created a hash and bind it to a prticular partion.
 - Key is optional . With out key sending messages wont guarntees the ordering of the message as the consumer poll the
     messages from all partions at the same time.
 
 #### Steps to work on Kafka
 -  Start zookeeper
 -  start the broker
 -  create the topic 
         > kafka-topics.bat --create --topic fruit --bootstrap-server localhost:9092 --replication-factor 1 -- partions 4
 - create producers
         > kafka-console-producers.bat --broker-list localhost:9092 --topic fruit --property "key.separator = -" --property "parse-key=true
 - same way create/register producers
 
 #### Understanding Consumer Offset, Consumer Groups, and Message Consumption in Apache Kafka
     
 -  In this section ,I will write about the process consumer consuing information from Partions
 -  Consumer Offset - Position of a consumer in a specific partition of topic. It represents the latest message consumer has read.
 -  When a consumer group reads a message from a topic, each member of the group mantains its own offset and updates it as it consumes message.
 -  when consumer created - > it will assigned with a group id . One consumer grouop can have multiple consumers.
 -  Ok, Each consumer mantains its own offset that is nothing but the bookmark of the last read . 
 - All the offset stores in _consumer_offset named topic. _consumer_offset is the builtin topic in apache kafka that keeps track of the latest offset commited forv each partion of each consumer group.
 - The information in _consumer_offset used by kafka for reliabity of the consumet groups and to ensure that messages are not lost or duplicated.
 - Important - There is separate __consumer_offset for each consumer group.
 - The group co ordinator uses this information to manage the assignment of partitions to consumers and ensure that each partion is being consumed 
     by exactly one consumer in the group.
 - when consumer joins a consumer group,it sends the join request to the group coordinator
 - The G.C will determine which partition the consumer assigned to be.
 - STICKY FASHION --> Consumer will assigned to the same partion until its on the same Consumer group.
 
 #### Understanding Segments, Commit Log, and Retention Policy
 - Segments : Particular set of messages ,Ek partition me bahut sare messages rehete hai. Ek segement ka size we can define.
 - Commit Log : In the server.properties -> directory for commit log
                    All the messages stored in the commit log folder as .log files
                    As manay partions for a topic ,that many folders will be created
                    E.g. -> Topic name food with 4 partitions
                          food_0
                          food_1
  - Retentions Policy  : Two types 
                             Data Based policy -> after a size it will delete 
                            Time Based policy -> By default 168 hours and after that the file will deleted
 
  -  Actually data stores in .log file in encoded format and consumer decode it before uses.
 
 #### How to Make a Kafka Cluster with 3 Brokers: Understand Replication Factor.
    
 - A Kafka cluster is a distributed system that consists of multiple Kafka brokers. Each broker is a server that runs Kafka to manage and store message       data. Each will unique broker Id.
 - The replication factor refers to the number of copies of each message that are stored in the Kafka cluster for fault tolerance.
 
 -  When a topic is created with a replication factor of N, Kafka ensures that there are N replicas of each message distributed across the brokers in         the cluster. This allows for high availability and fault tolerance, as well as scalability for handling large volumes of data.
 -  E.g.  One Zoo keeper and 3 Brokers 
        Create topic command 
        kafka-topics.bat --create --topic gadgets --bootstrap-server localhost:9092,localhost:9093,localhost:9094 --replication-factor 3 --partition 3
        In this 9092/9093/9094 are the brokers and replication fator 3 means creates 3 copies
        But when producer sends message,It will send to one broker who is the leader for that partion and then it will replicate inn other two.
        Similarly we can create prodcuers using command
        kafka -consumer-console.bat --bootsrtap-server --from-begining
 
 #### ISR in Kafka
 
 -  In Sync Replica . To see the list of topics kafka-topics.bat --describe
    Lets say one broker down ,the automatically leader will be assigned in sync
 
 #### Kafka Producer And Consumer Example In Java Spring Boot
 
 - Will share the link later here (main depencey is springframework-kafka )
 
 For [Video](https://www.youtube.com/watch?v=vmuZaT6JpCM&list=PLA3GkZPtsafbAjKYkhWnD6GdhRtm6JrD1&index=10) refernce
 
 
 **[⬆ Back to Top](#table-of-contents)** 
 
 </details>
 
 <details>
  <summary>Interview Questions</summary>
 
  ### Usages
 
 ```
 a.Kafka is a useful solution for scenarios that require real-time data processing, application activity tracking, and monitoring. 
 b.At the same time, Kafka  should not be utilized for on-the-fly data conversions, 
 data storage, or when a simple task queue is all that is required.
 
 ```
 ### [Important Link and Use cases Paypal](https://medium.com/paypal-tech/kafka-consumer-benchmarking-c726fbe4000)
 ### [Why Kafka is very fast](https://www.youtube.com/watch?v=UNUz1-msbOM)
 ### [Kafka Stream - Must reacd Book](https://assets.confluent.io/m/7997a914c1a19b5?mkt_tok=NTgyLVFIWC0yNjIAAAGGApzv7utiTseX[…]yqvKtp86XezuCYCO30eyP63XV8MjOSS5737KVpPO1BXbiPx5soDrNGE3YDA )
 ### [How linkedin works?](https://engineering.linkedin.com/blog/2019/apache-kafka-trillion-messages)
 ### [POC](https://github.com/hardikSinghBehl/kafka-java-spring-boot-poc)
 ### [Blogs](https://www.linkedin.com/pulse/kafka-idempotent-producer-rob-golder/)
 ### [Blogs-2](https://medium.com/@shesh.soft/kafka-idempotent-producer-and-consumer-25c52402ceb9)
 
 ``` Real time question
 Concern is that I have key i.e. uuid along with that key I published the AVRO model to a topic if I republished with same key it is still getting published and I could see the message in Kafka Topic. I am using confluent kafka version 7.2.1 which uses Kafka version 3.2. If kafka version is greater and 3.0. It has by default safe producer where it enable.idempotance = true acks  = all.
 ```
 
 ```
 can we create dynamic consumer in kafka
?
My producer generates topics where prefix will be fixed
And I want all of those topics to be consumed by one consumer
Is it possible in kafka?
 ```
 
| No.       | Questions         |
| ------------- |:-------------|
 |1. | Tell me about some of the use cases where Kafka is not suitable.|
 |2. | Describe message compression in Kafka. What is the need of message compression in Kafka? |
 |3. | What do you understand about log compaction and quotas in Kafka?|
 |4. | Explain the four core API architecture that Kafka uses.|
 |5. | What do you mean by a Partition in Kafka?|
 |6. | What do you mean by zookeeper in Kafka and what are its uses?|
 |7. | Differentiate between Rabbitmq and Kafka.|
 |8. | What do you understand about Kafka MirrorMaker? |
 |9. | What do you mean by confluent kafka? What are its advantages?|
 |10. | How are partitions distributed in an Apache Kafka cluster? |
 |11. | What is the purpose of ISR in Apache Kafka?|
 |12. | [How you will handle 50K req per second because coping 50K messages to kafka will also take some time](#12)|
 |13. | Tell me about some of the use cases where Kafka is not suitable.|
 |14. | Describe message compression in Kafka. What is the need of message|
 |15. | Tell me about some of the use cases where Kafka is not suitable.|
 |16. | Describe message compression in Kafka. What is the need of message |
 |17. | Tell me about some of the use cases where Kafka is not suitable.|
 |18. | Describe message compression in Kafka. What is the need of message|
 |19. | Tell me about some of the use cases where Kafka is not suitable.|
 |20. | Describe message compression in Kafka. What is the need of message |
 
  ### 12
  
  ```Solutions:
   
 - To update metadata in Cassandra using Kafka with a high throughput of 50K requests per second, we can use the following strategies:

- Batch Processing: Instead of sending each message individually, we can batch them together and send them in larger batches. This reduces the overhead of sending multiple small messages, and helps to achieve higher throughput.
- Asynchronous Processing: We can process the incoming messages asynchronously, which means that the application can continue processing new requests while Kafka is still processing previous requests. This approach helps to minimize any delays caused by the processing of individual messages.
- Use of Kafka Connect: Kafka Connect is a scalable and reliable way to move data in and out of Kafka. We can use Kafka Connect to integrate Cassandra and Kafka, and leverage its capabilities to manage large amounts of data with high throughput.
- Partitioning: We can partition the data across multiple Kafka topics to distribute the load across multiple Kafka brokers. This approach helps to achieve better parallelism and scalability, and allows us to handle high loads of incoming data.
- Optimization of Kafka settings: We can optimize the Kafka settings such as batch size, compression, and buffer sizes to increase the overall throughput of Kafka.

```

 There are many ways to create objects in javascript as below

**[⬆ Back to Top](#table-of-contents)**

</details>

```
